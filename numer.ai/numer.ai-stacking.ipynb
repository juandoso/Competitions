{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking (also called meta ensembling) is a model ensembling technique used to combine information from multiple predictive models to generate a new model. Often times the stacked model (also called 2nd-level model) will outperform each of the individual models due its smoothing nature and ability to highlight each base model where it performs best and discredit each base model where it performs poorly. For this reason, stacking is most effective when the base models are significantly different. \n",
    "\n",
    "http://blog.kaggle.com/2016/12/27/a-kagglers-guide-to-model-stacking-in-practice/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "workdir = \"/home/ubuntu/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(workdir+'numerai_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'feature1', u'feature2', u'feature3', u'feature4', u'feature5',\n",
       "       u'feature6', u'feature7', u'feature8', u'feature9', u'feature10',\n",
       "       u'feature11', u'feature12', u'feature13', u'feature14', u'feature15',\n",
       "       u'feature16', u'feature17', u'feature18', u'feature19', u'feature20',\n",
       "       u'feature21', u'feature22', u'feature23', u'feature24', u'feature25',\n",
       "       u'feature26', u'feature27', u'feature28', u'feature29', u'feature30',\n",
       "       u'feature31', u'feature32', u'feature33', u'feature34', u'feature35',\n",
       "       u'feature36', u'feature37', u'feature38', u'feature39', u'feature40',\n",
       "       u'feature41', u'feature42', u'feature43', u'feature44', u'feature45',\n",
       "       u'feature46', u'feature47', u'feature48', u'feature49', u'feature50',\n",
       "       u'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"Fold\"] = np.random.choice(range(1, n_folds + 1), train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds_col = \"Fold\"\n",
    "target_col = \"target\"\n",
    "features = [u'feature1', u'feature2', u'feature3', u'feature4', u'feature5',\n",
    "       u'feature6', u'feature7', u'feature8', u'feature9', u'feature10',\n",
    "       u'feature11', u'feature12', u'feature13', u'feature14', u'feature15',\n",
    "       u'feature16', u'feature17', u'feature18', u'feature19', u'feature20',\n",
    "       u'feature21', u'feature22', u'feature23', u'feature24', u'feature25',\n",
    "       u'feature26', u'feature27', u'feature28', u'feature29', u'feature30',\n",
    "       u'feature31', u'feature32', u'feature33', u'feature34', u'feature35',\n",
    "       u'feature36', u'feature37', u'feature38', u'feature39', u'feature40',\n",
    "       u'feature41', u'feature42', u'feature43', u'feature44', u'feature45',\n",
    "       u'feature46', u'feature47', u'feature48', u'feature49', u'feature50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_by_folds(model, model_name, train_df1, folds_col, target_col, features_col): \n",
    "    train_df = train_df1.copy()\n",
    "    \n",
    "    folds = train_df[folds_col]\n",
    "    target = train_df[target_col]\n",
    "    data = train_df[features_col]\n",
    "    \n",
    "    for f in folds.unique():\n",
    "        train_i = folds != f\n",
    "        train1 = data[train_i]\n",
    "        test1 = data[-train_i]\n",
    "        y1 = target[train_i]\n",
    "        model.fit(train1.as_matrix(), y1.as_matrix().ravel())\n",
    "        y1_pred = model.predict_proba(test1.as_matrix())\n",
    "        train_df.loc[-train_i, model_name] = y1_pred[:,1]\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_predictions(model, train_df, test_df, target_col, features_col): \n",
    "    X_train = train_df[features_col].as_matrix()\n",
    "    y_train = train_df[target_col].as_matrix().ravel()\n",
    "    X_test = test_df[features_col].as_matrix()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:,1]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdata = pd.read_csv(workdir+'numerai_tournament_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = testdata[[\"t_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(workdir+'numerai_training_data_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 1 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "best_params = {'colsample_bytree': 0.3, 'learning_rate': 0.01, 'min_child_weight': 3.0, 'n_estimators': 400, 'subsample': 0.2, 'max_depth': 5, 'gamma': 0.95}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(**best_params)\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagged_model = BaggingClassifier(model, n_estimators=10, max_samples=0.9, max_features=0.9, bootstrap=False, n_jobs=1)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "best_model = CalibratedClassifierCV(base_estimator=bagged_model, method='sigmoid', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 56min 2s, sys: 6.8 s, total: 2h 56min 9s\n",
      "Wall time: 11min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train1 = predict_by_folds(best_model, \"XGBClassifier\", train, folds_col, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 25min 49s, sys: 18.8 s, total: 1h 26min 7s\n",
      "Wall time: 5min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = make_predictions(best_model, train, testdata, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.loc[:, \"XGBClassifier\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1models.append(\"XGBClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train1.to_csv(workdir+'numerai_training_data_folds.csv', index=False)\n",
    "#predictions.to_csv(workdir+'numerai_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Model 2: RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "best_params = {'min_samples_split': 4, 'n_estimators': 1500}\n",
    "best_params[\"n_jobs\"] =  -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(**best_params)\n",
    "best_model = CalibratedClassifierCV(base_estimator=model, method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 52min 26s, sys: 25.4 s, total: 3h 52min 51s\n",
      "Wall time: 15min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train1 = predict_by_folds(best_model, \"RandomForestClassifier\", train1, folds_col, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 5min 56s, sys: 12.4 s, total: 2h 6min 8s\n",
      "Wall time: 8min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = make_predictions(best_model, train, testdata, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.loc[:, \"RandomForestClassifier\"] = prediction\n",
    "l1models.append(\"RandomForestClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.to_csv(workdir+'numerai_training_data_folds.csv', index=False)\n",
    "predictions.to_csv(workdir+'numerai_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3: k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "best_params = {'n_neighbors': 900}\n",
    "best_params[\"n_jobs\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(**best_params)\n",
    "best_model = CalibratedClassifierCV(base_estimator=model, method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 18min 21s, sys: 2.92 s, total: 4h 18min 24s\n",
      "Wall time: 17min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train1 = predict_by_folds(best_model, \"KNeighborsClassifier\", train1, folds_col, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 11min 1s, sys: 2.35 s, total: 5h 11min 4s\n",
      "Wall time: 20min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = make_predictions(best_model, train, testdata, target_col, features)\n",
    "predictions.loc[:, \"KNeighborsClassifier\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1models.append(\"KNeighborsClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.to_csv(workdir+'numerai_training_data_folds.csv', index=False)\n",
    "predictions.to_csv(workdir+'numerai_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagged_model = BaggingClassifier(model, n_estimators=10, max_samples=0.9, max_features=0.9, bootstrap=False, n_jobs=-1)\n",
    "best_model = CalibratedClassifierCV(base_estimator=bagged_model, method='sigmoid', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 s, sys: 10.2 s, total: 28 s\n",
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train1 = predict_by_folds(best_model, \"NaiveBayes\", train1, folds_col, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.4 s, sys: 3.44 s, total: 12.8 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = make_predictions(best_model, train, testdata, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.loc[:, \"NaiveBayes\"] = prediction\n",
    "l1models.append(\"NaiveBayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.to_csv(workdir+'numerai_training_data_folds.csv', index=False)\n",
    "predictions.to_csv(workdir+'numerai_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 5: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "model = LogisticRegressionCV(max_iter=500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=500,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train[features], train[target_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0059948425031894088"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = model.C_[0]\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500, C=C) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bagged_model = BaggingClassifier(model, n_estimators=10, max_samples=0.9, max_features=0.9, bootstrap=False, n_jobs=-1)\n",
    "best_model = CalibratedClassifierCV(base_estimator=bagged_model, method='sigmoid', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 10.2 s, total: 28.4 s\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train1 = predict_by_folds(best_model, \"LogisticRegression\", train1, folds_col, target_col, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.38 s, sys: 3.34 s, total: 12.7 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prediction = make_predictions(best_model, train, testdata, target_col, features)\n",
    "predictions.loc[:, \"LogisticRegression\"] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1models.append(\"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1.to_csv(workdir+'numerai_training_data_folds.csv', index=False)\n",
    "predictions.to_csv(workdir+'numerai_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2 = train1[l1models]\n",
    "target = train[target_col]\n",
    "test2 = predictions[l1models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=500,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegressionCV(max_iter=500, n_jobs=-1)\n",
    "model2.fit(train2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('XGBClassifier', 1.4024466949162022),\n",
       " ('RandomForestClassifier', 0.8456356192421759),\n",
       " ('KNeighborsClassifier', 0.56326595638255461),\n",
       " ('NaiveBayes', 0.31091337980485001),\n",
       " ('LogisticRegression', 1.7201707132887152)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(l1models, model2.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction2 = model2.predict_proba(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(workdir+\"example_predictions.csv\")\n",
    "results[\"probability\"] = prediction2[:,1]\n",
    "results.to_csv(workdir+\"submission_stacked_lr_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*submission_stacked_lr_1.csv has logloss of 0.689.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
