{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "data_path = \"/home/ubuntu/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Dataset (train and val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5103)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "img_size=(320, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3020 images belonging to 8 classes.\n",
      "Found 376 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_path+\"train/\"+'1trainDir',\n",
    "        target_size=img_size, \n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', \n",
    "        shuffle=True)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        data_path+\"train/\"+'1valDir',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "train_n = train_generator.N\n",
    "val_n = validation_generator.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALB': 0,\n",
       " 'BET': 1,\n",
       " 'DOL': 2,\n",
       " 'LAG': 3,\n",
       " 'NoF': 4,\n",
       " 'OTHER': 5,\n",
       " 'SHARK': 6,\n",
       " 'YFT': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(3, img_size[0], img_size[1]), border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.333))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.333))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.333))\n",
    "\n",
    "model.add(Convolution2D(256, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.333))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "checkpoints = ModelCheckpoint(filepath=data_path+\"best_weights.hdf5\", verbose=0, save_best_only=True)\n",
    "callsbacks = [early_stopping, checkpoints]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "3020/3020 [==============================] - 69s - loss: 1.8506 - acc: 0.3497 - val_loss: 1.9704 - val_acc: 0.4202\n",
      "Epoch 2/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.7574 - acc: 0.4159 - val_loss: 1.9766 - val_acc: 0.4282\n",
      "Epoch 3/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.7111 - acc: 0.4295 - val_loss: 1.9046 - val_acc: 0.4149\n",
      "Epoch 4/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.6952 - acc: 0.4414 - val_loss: 1.9325 - val_acc: 0.4335\n",
      "Epoch 5/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.6887 - acc: 0.4437 - val_loss: 1.8870 - val_acc: 0.4468\n",
      "Epoch 6/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.6762 - acc: 0.4467 - val_loss: 1.8224 - val_acc: 0.4202\n",
      "Epoch 7/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.6612 - acc: 0.4450 - val_loss: 1.8529 - val_acc: 0.4202\n",
      "Epoch 8/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.6510 - acc: 0.4487 - val_loss: 1.8437 - val_acc: 0.4282\n",
      "Epoch 9/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.6325 - acc: 0.4517 - val_loss: 1.8400 - val_acc: 0.4149\n",
      "Epoch 10/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.6108 - acc: 0.4523 - val_loss: 1.7854 - val_acc: 0.4229\n",
      "Epoch 11/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.6007 - acc: 0.4573 - val_loss: 1.7815 - val_acc: 0.4202\n",
      "Epoch 12/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.5977 - acc: 0.4553 - val_loss: 1.8004 - val_acc: 0.4415\n",
      "Epoch 13/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.5652 - acc: 0.4642 - val_loss: 1.7250 - val_acc: 0.4149\n",
      "Epoch 14/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.5644 - acc: 0.4626 - val_loss: 1.7728 - val_acc: 0.4282\n",
      "Epoch 15/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.5471 - acc: 0.4659 - val_loss: 1.6483 - val_acc: 0.4415\n",
      "Epoch 16/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.5380 - acc: 0.4798 - val_loss: 1.6519 - val_acc: 0.4388\n",
      "Epoch 17/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.5227 - acc: 0.4825 - val_loss: 1.6392 - val_acc: 0.4388\n",
      "Epoch 18/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.5092 - acc: 0.4758 - val_loss: 1.5775 - val_acc: 0.4495\n",
      "Epoch 19/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.4899 - acc: 0.4927 - val_loss: 1.6021 - val_acc: 0.4867\n",
      "Epoch 20/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.4525 - acc: 0.5026 - val_loss: 1.4776 - val_acc: 0.4840\n",
      "Epoch 21/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.4685 - acc: 0.4917 - val_loss: 1.5539 - val_acc: 0.4761\n",
      "Epoch 22/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.4604 - acc: 0.4987 - val_loss: 1.5101 - val_acc: 0.5080\n",
      "Epoch 23/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.4241 - acc: 0.5053 - val_loss: 1.4326 - val_acc: 0.4787\n",
      "Epoch 24/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.4291 - acc: 0.5136 - val_loss: 1.4905 - val_acc: 0.4973\n",
      "Epoch 25/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.4301 - acc: 0.5063 - val_loss: 1.4225 - val_acc: 0.5053\n",
      "Epoch 26/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.4044 - acc: 0.5129 - val_loss: 1.4279 - val_acc: 0.4814\n",
      "Epoch 27/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.3820 - acc: 0.5195 - val_loss: 1.3906 - val_acc: 0.5160\n",
      "Epoch 28/75\n",
      "3020/3020 [==============================] - 63s - loss: 1.3783 - acc: 0.5242 - val_loss: 1.3847 - val_acc: 0.4920\n",
      "Epoch 29/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.3697 - acc: 0.5262 - val_loss: 1.3908 - val_acc: 0.4894\n",
      "Epoch 30/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.3490 - acc: 0.5242 - val_loss: 1.3939 - val_acc: 0.4814\n",
      "Epoch 31/75\n",
      "3020/3020 [==============================] - 63s - loss: 1.3360 - acc: 0.5417 - val_loss: 1.3420 - val_acc: 0.5027\n",
      "Epoch 32/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.3399 - acc: 0.5381 - val_loss: 1.3645 - val_acc: 0.4840\n",
      "Epoch 33/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.3181 - acc: 0.5401 - val_loss: 1.3156 - val_acc: 0.5000\n",
      "Epoch 34/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.3139 - acc: 0.5371 - val_loss: 1.3874 - val_acc: 0.4787\n",
      "Epoch 35/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.3184 - acc: 0.5394 - val_loss: 1.3399 - val_acc: 0.5000\n",
      "Epoch 36/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.2926 - acc: 0.5530 - val_loss: 1.3013 - val_acc: 0.5000\n",
      "Epoch 37/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.2765 - acc: 0.5530 - val_loss: 1.3238 - val_acc: 0.5027\n",
      "Epoch 38/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.2709 - acc: 0.5427 - val_loss: 1.3425 - val_acc: 0.4973\n",
      "Epoch 39/75\n",
      "3020/3020 [==============================] - 66s - loss: 1.2610 - acc: 0.5546 - val_loss: 1.3303 - val_acc: 0.5053\n",
      "Epoch 40/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.2479 - acc: 0.5500 - val_loss: 1.2350 - val_acc: 0.4973\n",
      "Epoch 41/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.2399 - acc: 0.5609 - val_loss: 1.2328 - val_acc: 0.5053\n",
      "Epoch 42/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.2466 - acc: 0.5586 - val_loss: 1.1732 - val_acc: 0.5399\n",
      "Epoch 43/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.2072 - acc: 0.5632 - val_loss: 1.2733 - val_acc: 0.5160\n",
      "Epoch 44/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.2214 - acc: 0.5623 - val_loss: 1.1222 - val_acc: 0.5718\n",
      "Epoch 45/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.2213 - acc: 0.5659 - val_loss: 1.1922 - val_acc: 0.5080\n",
      "Epoch 46/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.1993 - acc: 0.5692 - val_loss: 1.1798 - val_acc: 0.5452\n",
      "Epoch 47/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1853 - acc: 0.5801 - val_loss: 1.1948 - val_acc: 0.5771\n",
      "Epoch 48/75\n",
      "3020/3020 [==============================] - 63s - loss: 1.1955 - acc: 0.5785 - val_loss: 1.0673 - val_acc: 0.5931\n",
      "Epoch 49/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1529 - acc: 0.5884 - val_loss: 1.1862 - val_acc: 0.5505\n",
      "Epoch 50/75\n",
      "3020/3020 [==============================] - 64s - loss: 1.1922 - acc: 0.5728 - val_loss: 1.0950 - val_acc: 0.5691\n",
      "Epoch 51/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1489 - acc: 0.5844 - val_loss: 1.1163 - val_acc: 0.5479\n",
      "Epoch 52/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1373 - acc: 0.5924 - val_loss: 1.0995 - val_acc: 0.6090\n",
      "Epoch 53/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1196 - acc: 0.5914 - val_loss: 1.0465 - val_acc: 0.5824\n",
      "Epoch 54/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.1310 - acc: 0.5801 - val_loss: 1.1418 - val_acc: 0.5718\n",
      "Epoch 55/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1270 - acc: 0.5947 - val_loss: 1.0980 - val_acc: 0.5532\n",
      "Epoch 56/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.1232 - acc: 0.5887 - val_loss: 1.0919 - val_acc: 0.5638\n",
      "Epoch 57/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1023 - acc: 0.6070 - val_loss: 1.0395 - val_acc: 0.5559\n",
      "Epoch 58/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1136 - acc: 0.5944 - val_loss: 0.9832 - val_acc: 0.5824\n",
      "Epoch 59/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.1030 - acc: 0.6010 - val_loss: 1.0477 - val_acc: 0.5665\n",
      "Epoch 60/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.0927 - acc: 0.6053 - val_loss: 1.0603 - val_acc: 0.5931\n",
      "Epoch 61/75\n",
      "3020/3020 [==============================] - 67s - loss: 1.1031 - acc: 0.6017 - val_loss: 1.0158 - val_acc: 0.6170\n",
      "Epoch 62/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.0705 - acc: 0.6152 - val_loss: 1.0160 - val_acc: 0.5878\n",
      "Epoch 63/75\n",
      "3020/3020 [==============================] - 61s - loss: 1.0527 - acc: 0.6119 - val_loss: 1.0381 - val_acc: 0.5771\n",
      "Epoch 64/75\n",
      "3020/3020 [==============================] - 62s - loss: 1.0657 - acc: 0.6089 - val_loss: 1.0573 - val_acc: 0.5665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15441d4cd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=train_n,\n",
    "        nb_epoch=75,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=val_n,\n",
    "        callbacks=callsbacks, \n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(data_path+\"best_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 381 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        data_path+'train/'+'1testDir',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "test_n = test_generator.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loss, Accuracy: \n",
      "[0.91526978300625261, 0.66929133600137369]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Loss, Accuracy: \")\n",
    "print(model.evaluate_generator(test_generator, val_samples=test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'ALB', 1: 'BET', 2: 'DOL', 3: 'LAG', 4: 'NoF', 5: 'OTHER', 6: 'SHARK', 7: 'YFT'}\n"
     ]
    }
   ],
   "source": [
    "classes = {v: k for k, v in train_generator.class_indices.iteritems()}\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_test = []\n",
    "Y_preds = []\n",
    "batch_ind = test_generator.batch_index\n",
    "for X_batch, Y_batch in test_generator:\n",
    "    y_pred = model.predict_classes(X_batch, verbose=0)\n",
    "    Y_test.extend(np.argmax(Y_batch,axis=1))\n",
    "    Y_preds.extend(y_pred)\n",
    "    if test_generator.batch_index == batch_ind:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = range(len(classes.keys()))\n",
    "for k,v in classes.iteritems():\n",
    "    names[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ALB       0.65      0.96      0.78       180\n",
      "        BET       0.00      0.00      0.00        19\n",
      "        DOL       0.00      0.00      0.00        13\n",
      "        LAG       0.00      0.00      0.00         8\n",
      "        NoF       0.89      0.75      0.81        44\n",
      "      OTHER       0.00      0.00      0.00        24\n",
      "      SHARK       0.82      0.64      0.72        14\n",
      "        YFT       0.60      0.51      0.55        79\n",
      "\n",
      "avg / total       0.56      0.67      0.60       381\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_preds, target_names=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[173   0   0   0   3   0   0   4]\n",
      " [ 14   0   0   0   0   0   2   3]\n",
      " [  2   0   0   0   0   0   0  11]\n",
      " [  6   0   0   0   1   0   0   1]\n",
      " [  6   0   0   0  33   0   0   5]\n",
      " [ 22   0   0   0   0   0   0   2]\n",
      " [  4   0   0   0   0   0   9   1]\n",
      " [ 39   0   0   0   0   0   0  40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, Y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(data_path+\"Simple_Keras-model2.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(data_path+'Simple_Keras-model2.h5') \n",
    "\n",
    "# serialize class indices to a numpy file npy\n",
    "np.save('/home/ubuntu/data/Simple_Keras-model2-classes.npy', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "def get_image_as_X(path_to_image_file, target_size, dim_ordering='th', rescale=1./255):\n",
    "    img = load_img(path_to_image_file, grayscale=False, target_size=target_size)\n",
    "    x = img_to_array(img, dim_ordering=dim_ordering)\n",
    "    #x = image_data_generator.standardize(x)\n",
    "    x *= rescale\n",
    "    return np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "test_path = data_path + \"test_stg1/\"\n",
    "imaglist = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(test_path):\n",
    "    imaglist.extend(filenames)\n",
    "    break\n",
    "predictions = []\n",
    "for element in imaglist:\n",
    "    x = get_image_as_X(test_path + \"/\" + element, img_size)\n",
    "    p = model.predict_proba(x, batch_size=1, verbose=0)\n",
    "    predictions.extend(p)\n",
    "test_id = imaglist[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def create_submission(path, predictions, test_id, info):\n",
    "    result1 = pd.DataFrame(predictions, columns=['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT'])\n",
    "    result1.loc[:, 'image'] = pd.Series(test_id, index=result1.index)\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_' + info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print(\"Writing \" + sub_file)\n",
    "    result1.to_csv(path+sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission_Simple_Keras_2_2016-12-12-04-02.csv\n"
     ]
    }
   ],
   "source": [
    "create_submission(data_path, predictions, test_id, \"Simple_Keras_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Public Score: 1.25864 (multi-class logarithmic loss.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
